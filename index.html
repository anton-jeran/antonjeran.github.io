<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0043)http://vision.princeton.edu/people/shurans/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


    <title>Anton Jeran Ratnarajah</title>


    <link href="./css" rel="stylesheet">
    <link rel="stylesheet" href="./style-seanzw.css" type="text/css" media="screen">

    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-126741439-1', 'auto');
        ga('send', 'pageview');

    </script>


</head>


<body>

    <div id="all">
        <div id="all-bio">
            <br>
            <div style="text-align:center">
                <h1>Anton Jeran Ratnarajah</h1>
                <h7> <a href="mailto:jeran@umd.edu">Mail</a>,
                    <a href="https://www.linkedin.com/in/anton-jeran-ratnarajah-78663099/">Linkedin</a>,
                    <a href="https://github.com/anton-jeran">GitHub</a>,
                    <a href="https://www.youtube.com/channel/UCyFib_CagIroRVyEjnA7_LQ">YouTube</a>,
                    <a href="https://scholar.google.com/citations?user=I_CcbVcAAAAJ">Google Scholar</a>,
                     <a href="https://www.researchgate.net/profile/Anton-Ratnarajah">Researchgate</a>,
                    <a target="_blank" href="./CV.pdf"> CV </a></h7>
            </div>
            <br>
            I am a 5th PhD student in Electrical and Computer Engineering at <a href="https://ece.umd.edu/"> University of Maryland-College Park</a> advised by <a href="https://www.cs.umd.edu/people/dmanocha/">Prof.&nbsp;Dinesh&nbsp;Manocha</a>. I am broadly interested in building machine learning models to create high quality sound experience in interactive applications. My current line of research is learning-based  <a href="https://gamma.umd.edu/researchdirections/sound/main">sound synthesis and propogation</a> for AR and VR applications and  <a href="https://gamma.umd.edu/researchdirections/speech/main">audio/speech processing applications</a>.
            
            <br><br>

            <br><br>
        </div>

        <div id="all-photo">
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <img src="./smc.jpg"  width =25% >
            <img src="./nanyang.jpg"  width =25% >
            <img src="./ict.jpg"  width =25% >
            <img src="./best.jpg" width =25% >
            </tr>
            </table>           
            
        </div>

        <div class="all-info">
            <h1>Research</h1>
            <table id="Publications">
                <tbody>
                    <tr>
                        <td><img src="./m3.png" width="220px"></td>
                        <td>
                            <p>
                                <b>M3-AUDIODEC: MULTI-CHANNEL MULTI-SPEAKER MULTI-SPATIAL AUDIO CODEC</b><br>
                                <b>Anton Jeran Ratnarajah</b>, <a href="https://scholar.google.com/citations?user=4nGncN4AAAAJ">Shi-Xiong Zhang</a>, <a href="https://scholar.google.com/citations?user=tMY31_gAAAAJ">Dong Yu</a> <br>
                                <b>Arxiv</b><br>
                                <a href="https://github.com/anton-jeran/MULTI-AUDIODEC">Code</a>&nbsp;|&nbsp;
                                <a href="https://arxiv.org/pdf/2309.07416.pdf">Paper</a>&nbsp;|&nbsp;
                                <a href="https://anton-jeran.github.io/MAD/">Webpage</a>
                            </p>
                        </td>
                    </tr>
                     <tr>
                        <td><img src="./scene2bir.jpg" width="220px"></td>
                        <td>
                            <p>
                                <b>Listen2Scene: Interactive material-aware binaural sound propagation for reconstructed 3D scenes</b><br>
                                <b>Anton Jeran Ratnarajah</b>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a> <br>
                                <b>Arxiv</b><br>    
                                <a href="https://github.com/anton-jeran/Listen2Scene">Code</a>&nbsp;|&nbsp;                           
                                <a href="https://arxiv.org/abs/2302.02809">Paper</a>&nbsp;|&nbsp;                                                 
                                <a href="https://anton-jeran.github.io/Listen2Scene/">Webpage</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td><img src="./META.png" width="220px"></td>
                        <td>
                            <p>
                                <b>Towards Improved Room Impulse Response Estimation for Speech Recognition</b><br>
                                <b>Anton Jeran Ratnarajah</b>, Ishwarya Ananthabhotla, <a href="https://www.vamsiithapu.com/">Vamsi Krishna Ithapu</a>, Pablo Hoffmann, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>,  <a href="https://scholar.google.com/citations?user=S_S6SZAAAAAJ">Paul Calamia</a> <br>
                                <b>ICASSP 2023</b><br>                                
                                <a href="https://arxiv.org/pdf/2211.04473.pdf">Paper</a>&nbsp;|&nbsp;                    
                                <a href="https://anton-jeran.github.io/S2IR/">Webpage</a>&nbsp;|&nbsp;
                                <a href="https://www.youtube.com/watch?v=65VoVLBUdg4">Video</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td><img src="./mesh2ir.png" width="220px"></td>
                        <td>
                            <p>
                                <b>MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes</b><br>
                                <b>Anton Jeran Ratnarajah</b>, Zhenyu Tang,Rohith Aralikatti,  <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a></a> <br>
                                <b>ACM Multimedia 2022 (Oral)</b><br>
                                <a href="https://github.com/anton-jeran/MESH2IR">Code</a>&nbsp;|&nbsp;
                                <a href="https://arxiv.org/pdf/2205.09248.pdf">Paper</a>&nbsp;|&nbsp;
                                <a href="https://www.youtube.com/watch?v=TUcueAmAbio">Video</a>&nbsp;|&nbsp;
                                <a href="https://anton-jeran.github.io/M2IR/">Webpage</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td><img src="./archi1.png" width="220px"></td>
                        <td>
                            <p>
                                <b>FAST-RIR: FAST NEURAL DIFFUSE ROOM IMPULSE RESPONSE GENERATOR</b><br>
                                <b>Anton Jeran Ratnarajah</b>, <a href="https://scholar.google.com/citations?user=4nGncN4AAAAJ">Shi-Xiong Zhang</a>,  Meng Yu, Zhenyu Tang, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>, <a href="https://scholar.google.com/citations?user=tMY31_gAAAAJ">Dong Yu</a> <br>
                                <b>ICASSP 2022</b><br>
                                <a href="https://github.com/anton-jeran/FAST-RIR">Code</a>&nbsp;|&nbsp;
                                <a href="https://arxiv.org/pdf/2110.04057.pdf">Paper</a>&nbsp;|&nbsp;
                                <a href="https://www.youtube.com/watch?v=1I8Rr7a2o0k">Video</a>&nbsp;|&nbsp;
                                <a href="https://anton-jeran.github.io/FRIR/">Webpage</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td><img src="./IR1.png" width="220px"></td>
                        <td>
                            <p>
                                <b>IR-GAN: Room impulse response generator for far-field speech recognition</b><br>
                                <b>Anton Jeran Ratnarajah</b>, Zhenyu Tang, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a> <br>
                                <b>INTERSPEECH 2021</b><br>
                                <a href="https://github.com/GAMMA-UMD/IR-GAN">Code</a>&nbsp;|&nbsp;
                                <a href="https://www.youtube.com/watch?v=_v5rDmDXvD0">Video</a>&nbsp;|&nbsp;
                                <a href="https://www.isca-speech.org/archive/interspeech_2021/ratnarajah21_interspeech.html">Paper</a> &nbsp;|&nbsp;
                                <a href="https://github.com/GAMMA-UMD/IR-GAN/blob/main/slides/IR-GAN_final.pdf">Slides</a>
                            </p>
                        </td>
                    </tr>



                    <tr>
                        <td><img src="./tsrir.png" width="220px"></td>
                        <td>
                            <p>
                                <b>TS-RIR: Translated synthetic room impulse responses for speech augmentation </b><br>
                                <b>Anton Jeran Ratnarajah</b>, Zhenyu Tang, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a> <br>
                                <b>Accepted to IEEE ASRU 2021</b><br>
                                <a href="https://github.com/GAMMA-UMD/TS-RIR">Code</a>&nbsp;|&nbsp;
                                <a href="https://www.youtube.com/watch?v=gghzIMT8FCw">Video</a>&nbsp;|&nbsp;
                                <a href="https://arxiv.org/pdf/2103.16804.pdf">Paper</a> &nbsp;|&nbsp;
                                <a href="https://github.com/GAMMA-UMD/TS-RIR/blob/main/slides/ts-rir_final.pdf">Slides</a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td><img src="./curr.png" width="220px"></td>
                        <td>
                            <p>
                                <b>IMPROVING REVERBERANT SPEECH SEPARATION WITH MULTI-STAGE TRAINING AND CURRICULUM LEARNING</b><br>
                                Rohith Aralikatti, <b>Anton Jeran Ratnarajah</b>, Zhenyu Tang, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a> <br>
                                <b>Accepted to IEEE ASRU 2021</b><br>
                                <a href="https://arxiv.org/pdf/2107.09177.pdf">Paper</a>
                            </p>
                        </td>
                    </tr>
                    
                    <tr>
                        <td><img src="./synopsis.png" width="220px"></td>
                        <td>
                            <p>
                                <b>Moving Object Based Collision-Free Video Synopsis</b><br>
                                <b>Anton Jeran Ratnarajah</b>, Sahani Goonetilleke, Dumindu Tissera, Kapilan Balagopalan, <a href="https://www.ranga.staff.uom.lk/">Ranga Rodrigo</a> <br>
                                <b>2018 IEEE International Conference on Systems, Man, and Cybernetics</b><br>
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8616283">Paper</a>
                            </p>
                        </td>
                    </tr>
                    

                </tbody>
            </table>

        </div>

          <div class="all-info">
            <h1>Education</h1>
                        <table id="Education">
                <tbody>

                    <tr>
                        <td><img src="./umd.jpg" width="220px"></td>
                        <td>
                            <p>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>PhD in Electrical and Computer Engineering</b><br>
                                <b>Cumulative GPA: 3.86 / 4</b><br>
                                <b>Aug. 2019 - Present (2024 expected)</b><br>               
                                                                                       
                            </p>
                        </td>
                    </tr>

                    <tr>
                        <td><img src="./mora.png" width="220px"></td>
                        <td>
                            <p>
                                <b>University of Moratuwa, Moratuwa, Sri Lanka</b><br>
                                <b>Bachelor of Science in Engineering</b><br>
                                <b>Cumulative GPA: 3.91 / 4.2</b><br>
                                <b>Feb. 2014 - Jan. 2018</b><br>               
                                                                                       
                            </p>
                        </td>
                    </tr>

                                                  

                </tbody>
            </table>

        <div class="all-info">
            <h1>Work Experience</h1>
                        <table id="Work_Experience">
                <tbody>
                     <tr>
                    <td><img src="./tencent.jpg" width="220px"></td>
                        <td>
                            <p>
                                <b>Research Intern</b><br>
                                <b>Tencent America, Bellevue, Washington, United States</b><br>
                                <b>May. 2023 - Aug. 2023</b><br>                         
                                Implemented an innovative neural spatial audio codec for efficient compression of multi-channel (binaural) speech in both single and multi-speaker scenarios while retaining the spatial location information of each speaker.


                                
                            </p>
                        </td>
                    </tr>
                    <tr>
                    <td><img src="./meta_icon.png" width="220px"></td>
                        <td>
                            <p>
                                <b>Research Scientist Intern</b><br>
                                <b>META Reality Labs, Redmond, Washington, United States</b><br>
                                <b>May. 2022 - Nov. 2022</b><br>                         
                                Implemented a blind room impulse response estimation system in the context of far-field speech recognition.
                                
                                
                            </p>
                        </td>
                    </tr>
                    <tr>
                    <td><img src="./tencent.jpg" width="220px"></td>
                        <td>
                            <p>
                                <b>Research Intern</b><br>
                                <b>Tencent America, Bellevue, Washington, United States</b><br>
                                <b>May. 2021 - Aug. 2021</b><br>                         
                                Implemented a neural-network-based fast diffuse room impulse response generator (FAST-RIR) for generating room impulse responses (RIRs) for a given acoustic environment.
                                

                                
                            </p>
                        </td>
                    </tr>

                     <tr>
                        <td><img src="./wave.png" width="220px"></td>
                        <td>
                            <p>
                                <b>Engineer</b><br>
                                <b>Wave Computing, Colombo, Sri Lanka</b><br>
                                <b>Feb. 2018 - Jul. 2019</b><br>                         
                                Developed machine learning applications for Wave Computing’s Dataflow Processing Unit (DPU) Architecture using Wave Flow Graph (WFG), a data flow description language developed by Wave Computing. Compiled and simulated the designs in Wave Computing’s complete EDA toolchain. Debugged and proposed suggestions to improve the toolchain and the architecture.
                                

                                
                            </p>
                        </td>
                    </tr>
        
                    <tr>
                        <td><img src="./nanyang.png" width="220px"></td>
                        <td>
                            <p>
                                <b>Research Intern</b><br>
                                <b>HESL Lab, Nanyang Technological University, Singapore</b><br>
                                <b>Aug. 2016 - Dec. 2016</b><br>                         
                                Successfully completed a project titled “Low complexity techniques for Vehicle Localization and Tracking" under the guidance of <a href="https://dr.ntu.edu.sg/cris/rp/rp00901"> Dr. Lam Siew Kei </a>.
                                

                                
                            </p>
                        </td>
                    </tr>
                   

            




                    

                </tbody>
            </table>
  <div class="all-info">
            <h1>Teaching Experience</h1>
                        <table id="Teaching_Experience">
                <tbody>
                    <tr>
                        
                        <td>
                            <p>
                                <b>ENEE 245: Digital Circuits and Systems Laboratory </b><br>
                                <b>Teaching Assistant for <a href="https://ece.umd.edu/clark/faculty/394/Manoj-Franklin"> Professor Manoj Franklin </a> </b><br>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>Spring 2022</b><br> 
                                <br>
                                <br>

                                <b>CMSC 742: Algorithms in Machine Learning: Guarantees and Analyses </b><br>
                                <b>Teaching Assistant for <a href="http://furong-huang.com/"> Professor Furong Huang </a> </b><br>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>Fall 2021</b><br> 
                                <br>
                                <br> 


                                <b>ENEE 630: Advanced Digital Signal Processing </b><br>
                                <b>Teaching Assistant for <a href="http://www.cspl.umd.edu/kjrliu/"> Professor K. J. Ray Liu </a> </b><br>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>Fall 2020</b><br>
                                <br>
                                <br>
                                                               

                                <b>ENEE 425: Digital Signal Processing </b><br>
                                <b>Teaching Assistant for <a href="https://user.eng.umd.edu/~behtash/"> Professor Behtash Babadi </a> </b><br>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>Spring 2020</b><br>    
                                <br>
                                <br>

                                                               

                                <b>ENEE 425: Digital Signal Processing </b><br>
                                <b>Teaching Assistant for <a href="https://en.wikipedia.org/wiki/Carol_Espy-Wilson"> Professor Carol Espy-Wilson </a> </b><br>
                                <b>University of Maryland - College Park, College Park, MD, USA</b><br>
                                <b>Fall 2019</b><br> 
                                <br>
                                <br>



                               

                                
                            </p>
                        </td>
                    </tr>
                                       

                </tbody>
            </table>

         
        </div>
    </div>
</body>

</html>
